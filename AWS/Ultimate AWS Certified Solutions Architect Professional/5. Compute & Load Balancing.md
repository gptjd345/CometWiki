# I. Solution Architecture on AWS
사용자가 응용 프로그램에 엑세스할 때 접속하는 순서

## 1. DNS Layer
* *Route 53*
## 2-1. CDN Layer
* *CloudFront*
* 정적 콘텐츠는 전 세계에 확산되고 CDN 계층, 콘텐츠 전송 네트워크를 통해 캐싱된다.
* CloudFront는 다음과 같은 방식으로 작동할 수 있다:
	1. **S3나 Glacier에서 정적 콘텐츠를 가져오기**: 
	   일반적인 사용 사례입니다. CloudFront는 S3 버킷이나 Glacier에 저장된 콘텐츠를 캐싱하여 전 세계 사용자에게 빠르게 제공합니다.
	2. **사용자 지정 소스에서 콘텐츠 가져오기**: 
	   사용자가 지정한 다른 서버나 데이터베이스에서 콘텐츠를 가져올 수 있습니다. 예를 들어, 사용자가 운영하는 웹 서버나 API 서버에서도 콘텐츠를 가져와 캐싱하고 배포할 수 있습니다.
* <font color="#7f7f7f">User -> CDN Layer -> Static Assets Layer </font>
## 2-1. Web Layer
* *CLB, ALB, NLB, API Gateway, Elastic IP*
* 웹 계층의 역할은 다음과 같다:
1. **사용자 요청 수신**: 
   사용자가 웹 브라우저나 모바일 앱을 통해 보낸 요청을 수신한다.
2. **동적 콘텐츠 처리**: 
   필요한 경우 동적인 콘텐츠를 처리한다.
4. **부하 분산 (Load Balancing)**: 
   여러 서버로 트래픽을 분산하여 특정 서버에 과부하가 걸리지 않도록 관리한다.
5. **요청 전달**: 
   수신한 요청을 컴퓨팅 계층으로 전달하여 실제 데이터 처리나 비즈니스 로직이 실행되도록 한다.
6. **응답 반환**: 
   컴퓨팅 계층에서 처리된 결과를 다시 사용자에게 반환한다.
## 3. Compute Layer
* *EC2, ASG, Lambda, ECS, Fargate, Batch, EMR*
## 4-1. Caching / Sesstion Layer
* *ElastiCache, DAX, DynamoDB, RDS*
## 4-2. Database Layer
* *RDS, Aurora, DynamoDB ElasticSearch, S3, Redshift*
## 4-3. Decoupling Orchestration Layer 
* *SQS, SNS, Kinesis Amazon MQ, Step Functions*
## 4-4. Storage Layer 
* *EBS, EFS, Instance Store* 
## 4-5. Static Assets Layer 
* *(storage) S3, Glacier*

# II. EC2
## EC2 Instance Types (EC2 Instance 패밀리)
* R: 많은 RAM이 필요한 애플리케이션(메모리 집약적인 작업에 최적화) – in-memory caches / databases
* C: 높은 CPU가 필요한 애플리케이션(CPU 집약적인 작업에 최적화) – compute / databases
* M: 균형 잡힌 성능이 필요한 애플리케이션('중간', CPU와 메모리의 균형이 잘 잡혀 있음) – general / web app
* I: 높은 로컬 I/O가 필요한 애플리케이션(인스턴스 스토리지에 최적화) – 고성능 databases / 데이터 웨어하우징
* G: GPU가 필요한 애플리케이션 – video rendering / machine learning
* T2 / T3: 버스트 가능한 인스턴스(최대 용량)  
* T2 / T3 - 무제한 : 무제한 버스트
* * 버스트(Burst)는 컴퓨팅 리소스, 특히 CPU 성능이 일시적으로 증가하는 것을 의미한다. 이를 통해 인스턴스가 평상시에는 기본 성능을 유지하다가 필요할 때 일시적으로 더 높은 성능을 발휘할 수 있다.
## EC2 - Placement Groups
배치 그룹을 사용하여 EC2 인스턴스의 배치를 전략으로 제어하는 방법
### 배치 그룹 전략

1. **Cluster (클러스터)**:
    
    - **용도**: 단일 가용성 영역(AZ) 내에서 인스턴스를 저지연 그룹으로 클러스터링.
    - **특징**: 인스턴스 간의 네트워크 지연 시간을 최소화하여 높은 성능을 요구하는 워크로드에 적합.
    - **예시**: 고성능 컴퓨팅(HPC) 애플리케이션.
2. **Spread (분산)**:
    
    - **용도**: 인스턴스를 기본 하드웨어 전체로 확산.
    - **특징**: 단일 하드웨어 장애로 인해 여러 인스턴스가 영향받지 않도록 인스턴스를 분산 배치.
    - **제한**: 그룹당 최대 7개의 인스턴스.
    - **예시**: 중요 애플리케이션, 고가용성이 요구되는 서비스.
3. **Partition (파티션)**:
    
    - **용도**: 인스턴스를 다양한 파티션으로 확산. 각 파티션은 다른 하드웨어 세트에 의존.
    - **특징**: 랙 수준의 장애를 피하기 위해 인스턴스를 여러 파티션에 분산 배치.
    - **확장성**: 그룹당 수백 개의 인스턴스까지 확장 가능.
    - **예시**: 대규모 분산 시스템(Hadoop, Cassandra, Kafka).

### 인스턴스를 배치 그룹으로 이동하거나 배치 그룹 밖으로 이동하는 방법

1. 인스턴스를 중지한다.
2. 중지 후, CLI를 사용하여 인스턴스의 배치 그룹을 수정한다.
    - **명령어**: `aws ec2 modify-instance-placement`
3. 변경 사항을 적용한 후, 인스턴스를 다시 시작한다.


이와 같은 전략을 통해 EC2 인스턴스의 배치 방식을 최적화하여 성능과 가용성을 높일 수 있다. 각 배치 전략은 특정한 요구사항에 맞게 설계되었으므로, 애플리케이션의 특성에 맞는 전략을 선택하는 것이 중요하다.

### 1. 배치 그룹 - Cluster (클러스터)

단일 가용성 영역(AZ) 내에서 인스턴스를 저지연 그룹으로 클러스터링하는 배치 전략이다. 이를 통해 인스턴스 간의 네트워크 지연 시간을 최소화하고 높은 네트워크 대역폭을 제공한다.

#### 장점

- **우수한 네트워크 성능**: Enhanced Networking을 활성화한 인스턴스 간의 대역폭이 최대 10Gbps에 달한다.
    - **Enhanced Networking**: 네트워크 성능을 향상시키기 위해 Amazon EC2에서 제공하는 기능으로, 높은 패킷 처리량과 낮은 지연 시간을 제공한다.
- **낮은 지연 시간**: 인스턴스들이 물리적으로 가까운 위치에 배치되어 네트워크 지연 시간이 최소화된다.
- **높은 네트워크 처리량**: 대량의 데이터 전송이 필요한 작업에서 높은 네트워크 처리량을 제공한다.

#### 단점

- **단일 장애점**: 랙에 장애가 발생하면 모든 인스턴스가 동시에 장애를 겪을 수 있다.
    - **랙 장애**: 물리적 하드웨어나 네트워크 장비의 문제가 발생할 경우, 해당 랙에 배치된 모든 인스턴스가 영향을 받는다.
    - **고가용성 문제**: 특정 랙에 모든 인스턴스를 집중 배치하므로, 고가용성 요구사항을 충족하기 어려울 수 있다.

#### 사용 사례

- **빅 데이터 작업**:
    - **특징**: 대량의 데이터를 빠르게 처리해야 하는 작업.
    - **예시**: 데이터 분석, 머신 러닝 모델 학습 등.
- **매우 낮은 지연 시간과 높은 네트워크 처리량이 필요한 애플리케이션**:
    - **특징**: 실시간 처리나 고성능 네트워킹이 필요한 애플리케이션.
    - **예시**: 고성능 컴퓨팅(HPC), 금융 거래 시스템, 실시간 게임 서버 등.

### 요약

클러스터 배치 그룹 전략은 매우 낮은 지연 시간과 높은 네트워크 처리량을 제공하여 고성능이 필요한 애플리케이션에 적합하다. 그러나 단일 장애점이 존재하므로, 고가용성이 중요한 경우에는 다른 배치 전략과 함께 사용하거나 가용성 영역(AZ)을 분산하여 배치하는 등의 추가적인 고가용성 설계를 고려해야 한다.

### 2. 배치 그룹 - Spread (분산)

각 인스턴스를 서로 다른 물리적 하드웨어에 배치하여 단일 장애점(Single Point of Failure)을 최소화하는 배치 전략이다. 이를 통해 인스턴스 간의 독립성을 높이고, 가용성을 극대화한다.

#### 장점

- **가용성 영역(AZ) 전반에 걸쳐 적용 가능**: 분산형 배치 그룹은 여러 가용성 영역에 걸쳐 인스턴스를 배치할 수 있어, 특정 가용성 영역의 장애로부터 보호할 수 있다.
- **동시 고장 위험 감소**: 인스턴스가 서로 다른 물리적 하드웨어에 배치되므로, 하나의 하드웨어 장애가 전체 시스템에 영향을 미치지 않는다.
- **독립성 보장**: 각 인스턴스가 서로 다른 물리적 하드웨어에 배치되므로, 인스턴스 간에 장애가 전파되지 않는다.

#### 단점

- **제한된 인스턴스 수**: 각 가용성 영역(AZ)당 퍼져요 배치 그룹 내에 최대 7개의 인스턴스만 배치할 수 있다.
    - **제한**: 대규모 애플리케이션을 운영하는 경우, 이 제한이 배포 전략에 영향을 미칠 수 있다.

#### 사용 사례

- **고가용성을 극대화해야 하는 애플리케이션**:
    - **특징**: 항상 서비스를 제공해야 하고, 장애가 발생하더라도 서비스 중단을 최소화해야 하는 애플리케이션.
    - **예시**: 금융 서비스, 의료 시스템 등.
- **각 인스턴스를 서로의 장애로부터 분리해야 하는 중요한 애플리케이션**:
    - **특징**: 하나의 인스턴스 장애가 다른 인스턴스에 영향을 미치지 않도록 설계해야 하는 애플리케이션.
    - **예시**: 데이터베이스 서버, 중요한 애플리케이션 서버 등.

### 요약

분산형 배치 그룹 전략은 인스턴스 간의 독립성을 강화하여 고가용성을 요구하는 애플리케이션에 적합하다. 이 전략은 여러 가용성 영역에 걸쳐 인스턴스를 배치할 수 있어, 특정 하드웨어나 가용성 영역의 장애로부터 애플리케이션을 보호한다. 다만, 가용성 영역당 인스턴스 수에 제한이 있으므로, 대규모 애플리케이션을 운영할 때는 이 점을 고려해야 한다.

### 3. 배치 그룹 - Partition (파티션)
#### 특징

- **AZ당 최대 7개의 파티션**: 하나의 가용 영역(AZ) 내에서 최대 7개의 파티션을 생성할 수 있다.
- **최대 100개의 EC2 인스턴스**: 한 파티션 배치 그룹 내에서 최대 100개의 EC2 인스턴스를 배포할 수 있다.
- **파티션 간 독립성**: 하나의 파티션 내 인스턴스는 다른 파티션의 인스턴스와 물리적 랙을 공유하지 않는다. 즉, 하나의 파티션에 장애가 발생해도 다른 파티션에 영향을 미치지 않는다.
- **메타데이터로 파티션 정보 접근 가능**: EC2 인스턴스는 메타데이터를 통해 자신이 속한 파티션 정보를 확인할 수 있다.

#### 사용 사례

- **HDFS (Hadoop Distributed File System)**: 대규모 데이터 분산 저장 및 처리를 위한 분산 파일 시스템.
- **HBase**: 대규모 데이터 저장을 위한 분산형 비관계형 데이터베이스.
- **Apache Cassandra (카산드라)**: 확장성과 고가용성을 제공하는 분산형 NoSQL 데이터베이스.

#### 장점

- **장애 격리**: 파티션 구조를 통해 특정 파티션에 장애가 발생하더라도 다른 파티션에는 영향을 미치지 않으므로, 고가용성을 유지할 수 있다.
- **데이터 분산 및 복제**: HDFS, HBase, 카산드라 같은 분산 시스템에서 데이터 분산 및 복제를 쉽게 관리할 수 있다.

#### 단점

- **설계 복잡성**: 파티션을 효율적으로 설계하는 데에 시간이 걸릴 수 있다.
- **제약 조건**: 파티션 수와 인스턴스 수에 제한이 있다.

### 요약

파티션 배치 그룹은 대규모 분산 시스템에서 데이터 복제 및 장애 격리를 효과적으로 관리할 수 있는 방법을 제공한다. 이러한 구조는 HDFS, HBase, 카산드라와 같은 시스템에서 특히 유용하다. 파티션 배치 그룹을 활용하면 특정 파티션에 장애가 발생하더라도 다른 파티션에 영향을 미치지 않아 시스템의 고가용성을 유지할 수 있다.\

## EC2 인스턴스 시작 유형

### 1. On-Demand Instances (온 디맨드 인스턴스)

- **특징**: 필요할 때 인스턴스를 시작하고 사용한 만큼만 비용을 지불하는 방식.
- **사용 사례**: 짧은 워크로드, 예측 가능한 가격, 신뢰성이 중요한 경우.
- **장점**: 초기 비용 없이 사용 가능, 유연성 및 확장성 제공.
- **단점**: 장기적으로는 비용이 높을 수 있음.

### 2. Spot Instances (스팟 인스턴스)

- **특징**: AWS의 유휴 컴퓨팅 자원을 저렴한 비용으로 사용할 수 있는 방식.
- **사용 사례**: 짧은 워크로드로 인스턴스가 예고 없이 종료될 수 있는 작업(예: 배치 처리, 데이터 분석).
- **장점**: 매우 저렴한 비용.
- **단점**: 신뢰할 수 없음, 인스턴스가 예고 없이 종료될 수 있음.

### 3.-1 Reserved 
* 최소 1년
* 최고 할인 -> 최저 할인: 모든 선불 > 부분 선불 > 선불 없음
#### 3.-1 Reserved Instances (예약 인스턴스)

- **특징**: 최소 1년 동안 인스턴스를 예약하여 할인된 가격으로 사용하는 방식.
- **사용 사례**: 긴 워크로드가 예상되는 경우.
- **장점**: 온 디맨드 인스턴스보다 저렴한 비용.
- **단점**: 장기 계약 필요, 유연성 제한.

#### 3-2. Convertible Reserved Instances

- **특징**: 예약 인스턴스의 유연한 버전으로, 예약 기간 동안 인스턴스 유형을 변경할 수 있음.
- **사용 사례**: 긴 워크로드가 예상되지만 인스턴스 유형의 유연성이 필요한 경우.
- **장점**: 인스턴스 유형 변경 가능, 할인된 가격.
- **단점**: 일반 예약 인스턴스보다 할인율이 낮을 수 있음.

### 4. Dedicated Instances (전용 인스턴스)

- **특징**: 다른 고객과 하드웨어를 공유하지 않는 인스턴스.
- **사용 사례**: 보안 및 규제 요구 사항으로 인해 하드웨어 격리가 필요한 경우.
- **장점**: 보안 및 격리 제공.
- **단점**: 비용이 높음.

### 6. Dedicated Hosts (전용 호스트)

- **특징**: 전체 물리적 서버를 예약하여 인스턴스 배치 및 물리적 서버 제어 가능.
- **사용 사례**: 코어 또는 CPU 소켓 수준에서 작동하는 소프트웨어 라이센스에 적합, 특정 규제 요구 사항이 있는 경우.
- **장점**: 인스턴스 배치 제어, 특정 라이센스 요구 사항 충족, 호스트 선호도 정의 가능.
- **단점**: 매우 높은 비용.

### 요약

각 EC2 인스턴스 시작 유형은 특정 사용 사례와 요구 사항에 맞춰 설계되었다. 온 디맨드 인스턴스는 유연성과 신뢰성이 높지만 비용이 비쌀 수 있고, 스팟 인스턴스는 매우 저렴하지만 신뢰성이 낮다. 예약 인스턴스와 Convertible Reserved 인스턴스는 장기 워크로드에 적합하며, 전용 인스턴스와 전용 호스트는 보안 및 규제 요구 사항을 충족한다. 사용자의 특정 요구 사항에 따라 적절한 인스턴스 유형을 선택하는 것이 중요하다.

## EC2 Graviton
AWS Graviton 프로세서는 AWS에서 자체 설계한 ARM 기반 프로세서로, 뛰어난 가격 대비 성능을 제공하는 것이 특징이다. Graviton, Graviton2, Graviton3 세대가 있으며, 각 세대는 이전 세대보다 성능과 효율성이 크게 향상되었다.

### AWS Graviton 특징

#### Graviton 프로세서

- **최고의 가격 성능**: AWS Graviton 프로세서는 뛰어난 가격 대비 성능을 제공한다.
- **지원 OS**: 다양한 리눅스 운영 체제 (Amazon Linux 2, RedHat, SUSE, Ubuntu)를 지원한다. 다만, 윈도우즈 인스턴스에서는 사용할 수 없다.

#### Graviton2

- **가격 성능**: 동급 x86 기반 인스턴스보다 40% 향상된 가격 성능을 제공한다.
- **사용 사례**: 앱 서버, 마이크로서비스, 고성능 컴퓨팅(HPC), CPU 기반 머신러닝, 비디오 인코딩, 게임, 인메모리 캐시 등.

#### Graviton3

- **성능**: Graviton2 대비 최대 3배 향상된 성능을 제공한다.
- **사용 사례**: Graviton2와 유사한 사용 사례에 더 높은 성능 요구 사항이 있는 작업에 적합하다.

### 사용 사례

- **앱 서버**: 웹 애플리케이션을 호스팅하는 서버.
- **마이크로서비스**: 작은 독립적 서비스로 구성된 애플리케이션.
- **고성능 컴퓨팅(HPC)**: 복잡한 연산 작업을 수행하는 컴퓨팅.
- **CPU 기반 머신러닝**: CPU를 활용한 머신러닝 작업.
- **비디오 인코딩**: 비디오 파일을 다른 형식으로 변환하는 작업.
- **게임**: 온라인 게임 서버.
- **인메모리 캐시**: 빠른 데이터 접근을 위해 메모리에 데이터를 저장하는 시스템.

### 요약

AWS Graviton 프로세서는 ARM 기반의 고성능, 저비용 프로세서로, 다양한 리눅스 운영 체제와 호환된다. Graviton2는 동급 x86 인스턴스 대비 40% 향상된 가격 성능을 제공하며, Graviton3는 Graviton2 대비 최대 3배 향상된 성능을 제공한다. Graviton 프로세서는 앱 서버, 마이크로서비스, 고성능 컴퓨팅, CPU 기반 머신러닝, 비디오 인코딩, 게임, 인메모리 캐시 등 다양한 사용 사례에 적합하다.

## EC2 메트릭
AWS EC2 인스턴스는 다양한 메트릭을 모니터링하여 인스턴스의 상태와 성능을 파악할 수 있다. 여기에는 CPU, 네트워크, 상태 확인, 디스크 관련 메트릭이 포함된다. 다만, RAM 사용량은 기본 제공 메트릭에 포함되지 않는다.

### EC2 메트릭

#### CPU 메트릭
* **CPU 사용률 + 신용 사용률/잔액**
- **CPU 사용률 (CPU Utilization)**: 인스턴스의 CPU 사용률을 측정한다.
- **CPU 신용 사용률/잔액 (CPU Credit Usage/Balance)**: T2, T3 인스턴스와 같은 버스트 가능한 인스턴스 유형에서 사용된다. 신용 사용률은 사용한 CPU 크레딧을, 신용 잔액은 남아 있는 CPU 크레딧을 나타낸다.

#### Network 메트릭
* **네트워크 입력/출력**
- **네트워크 입력 (Network In)**: 인스턴스로 들어오는 네트워크 트래픽을 측정한다.
- **네트워크 출력 (Network Out)**: 인스턴스에서 나가는 네트워크 트래픽을 측정한다.

#### Status Check(상태 확인) 메트릭

- **인스턴스 상태 (Instance Status)**: EC2 VM의 상태를 확인한다. 이는 인스턴스 자체의 소프트웨어와 네트워크 설정을 검사한다.
- **시스템 상태 (System Status)**: 기본 하드웨어의 상태를 확인한다. 이는 인스턴스가 실행되는 물리적 호스트의 상태를 검사한다.

#### Disk 메트릭

- **읽기/쓰기 (Read/Write Ops/Bytes)**: 인스턴스 스토어의 경우에만 해당된다. 디스크의 읽기 및 쓰기 작업 수와 바이트 수를 측정한다.

### 제외된 메트릭

- **RAM 사용률**: RAM 사용량과 관련된 메트릭은 기본 제공되지 않는다. RAM 사용량을 모니터링하려면 별도의 에이전트를 설치하거나 CloudWatch 커스텀 메트릭을 설정해야 한다.

### 요약

AWS EC2 인스턴스는 CPU 사용률, 네트워크 입력/출력, 상태 확인(인스턴스 상태 및 시스템 상태), 디스크 읽기/쓰기 메트릭을 제공한다. RAM 사용률은 기본 제공 메트릭에 포함되지 않으며, 이를 모니터링하려면 추가 설정이 필요하다. 이러한 메트릭을 통해 인스턴스의 성능과 상태를 효과적으로 모니터링할 수 있다.

## EC2 Instance Recovery
AWS EC2 인스턴스의 복구 절차는 인스턴스 상태와 시스템 상태를 확인하고, 문제가 발생했을 때 인스턴스를 복구하는 과정을 포함한다. 복구 시 인스턴스의 네트워크 설정 및 메타데이터 등이 유지된다.

### EC2 인스턴스 복구 절차
- EC2 Instance <-- monitor / Recovery -- ClouldWhatch Alarm (StatusCheckFailed_System)

#### 상태 확인

1. **인스턴스 상태 (Instance Status)**:
    
    - EC2 VM의 상태를 검사합니다. 소프트웨어 및 네트워크 설정과 관련된 문제를 확인한다.
    - 문제 발생 시, 인스턴스 재부팅 또는 다른 조치를 통해 문제 해결을 시도한다.
2. **시스템 상태 (System Status)**:
    
    - 기본 하드웨어와 호스트 시스템의 상태를 검사한다.
    - 하드웨어 관련 문제가 발견되면, AWS는 인스턴스를 자동으로 다른 물리적 호스트로 이동시켜 문제를 해결한다.

#### 복구

- **복구 조치**: 인스턴스가 비정상 상태일 때, AWS는 자동으로 인스턴스를 복구할 수 있다. 복구 과정에서는 다음 항목들이 유지된다:
    - **Private IP Address (개인 IP 주소)**: 인스턴스에 할당된 개인 IP 주소가 유지된다.
    - **Public IP Address (공용 IP 주소)**: 탄력적 IP(Elastic IP)를 사용하고 있는 경우, 공용 IP 주소도 유지된다.
    - **Elastic IP Address (탄력적 IP 주소)**: 탄력적 IP는 인스턴스가 복구된 후에도 동일하게 유지된다.
    - **Metadata (메타데이터)**: 인스턴스의 메타데이터와 사용자 데이터는 변경되지 않는다.
    - **Placement Group (배치 그룹)**: 인스턴스가 배치 그룹에 속해 있는 경우, 복구 후에도 동일한 배치 그룹에 속하게 된다.

### Amazon CloudWatch
AWS 리소스와 애플리케이션을 모니터링하고, 다양한 메트릭스와 로그를 수집하여 알람을 생성할 수 있는 서비스이다. CloudWatch Alarm을 사용하여 특정 조건이 충족될 때 자동으로 복구 작업을 수행하도록 설정할 수 있다.

### 요약

EC2 인스턴스의 상태 확인은 두 가지로 나뉩니다:

- **인스턴스 상태**: 인스턴스 자체의 소프트웨어 및 네트워크 설정을 검사한다.
- **시스템 상태**: 인스턴스가 실행되는 물리적 호스트의 상태를 검사한다.

인스턴스 복구 시 동일한 개인 IP, 공용 IP, 탄력적 IP, 메타데이터, 및 배치 그룹이 유지된다. 이를 통해 인스턴스가 원활하게 복구되고, 네트워크 설정 및 기타 중요한 정보가 손실되지 않도록 보장한다.

# III. High Performance Computing (HPC)
고성능 컴퓨팅(HPC)은 매우 복잡하고 계산 집약적인 작업을 수행하는 데 필요한 기술이다. 클라우드는 이러한 HPC 작업을 수행하기에 최적의 환경을 제공한다. 

## 클라우드에서 HPC의 이점

### 1. **즉각적인 리소스 생성**

- 클라우드는 필요할 때 순식간에 매우 많은 컴퓨팅 리소스를 생성할 수 있다.
- 물리적 하드웨어를 구매하고 설정하는 데 필요한 시간이 절약된다.

### 2. **확장성**

- 클라우드 환경에서는 필요한 만큼 리소스를 쉽게 확장할 수 있다.
- 추가 리소스를 활용하여 계산 시간을 단축하고 더 빠르게 결과를 도출할 수 있다.

### 3. **비용 효율성**

- 사용한 만큼만 비용을 지불하는 방식(Pay-as-you-go)으로, 리소스를 사용한 시간과 양에 따라 결제된다.
- 대규모 초기 투자 없이도 고성능 컴퓨팅을 활용할 수 있다.

### 4. **다양한 활용 분야**

- 클라우드 기반 HPC는 다양한 분야에서 활용될 수 있다:
    - **유전체학 (Genomics)**: 대규모 유전자 데이터 분석
    - **전산화학 (Computational Chemistry)**: 분자 모델링과 시뮬레이션
    - **재무위험 모델링 (Financial Risk Modeling)**: 복잡한 금융 모델 계산
    - **날씨 예측 (Weather Forecasting)**: 기상 데이터 분석 및 예측
    - **기계 학습 (Machine Learning)**: 대규모 데이터 셋을 활용한 모델 훈련
    - **딥 러닝 (Deep Learning)**: 신경망 모델의 훈련과 추론
    - **자율 주행 (Autonomous Driving)**: 자율 주행 차량의 시뮬레이션 및 데이터 처리

### 요약

고성능 컴퓨팅(HPC)은 클라우드에서 매우 효과적으로 수행될 수 있다. 클라우드는 즉각적인 리소스 생성, 뛰어난 확장성, 비용 효율성 등 많은 이점을 제공하며, 유전체학, 전산화학, 재무위험 모델링, 날씨 예측, 기계 학습, 딥 러닝, 자율 주행 등의 다양한 분야에서 활용될 수 있다. 클라우드 기반 HPC를 통해 복잡한 계산 작업을 더 빠르고 효율적으로 수행할 수 있다.


## HPC(고성능 컴퓨팅)를 수행하는 데 유용한 AWS 서비스

### 데이터 관리 및 전송

1. **AWS Direct Connect**:
    - 프라이빗 보안 네트워크를 통해 GB/s의 데이터를 클라우드로 이동.
2. **Snowball & Snowmobile**:
    - 대규모 데이터(PB 단위)를 클라우드로 이동.
3. **AWS DataSync**:
    - 온프레미스와 S3, EFS, FSx 간에 대용량 데이터를 이동. 특히 Windows 환경에서 유용.

### 컴퓨팅 및 네트워킹
<font color="#92d050">* 구분 중요</font>

1. **EC2 인스턴스**:
    
    - CPU 최적화, GPU 최적화 인스턴스 사용.
    - 비용 절감을 위한 Spot 인스턴스 / Spot Fleet + 자동 확장.
    - 네트워크 성능 향상을 위한 EC2 배치 그룹의 클러스터 사용.
    
2. **EC2 Enhanced Networking(EC2 향상된 네트워킹)(SR-IOV)**:
    
    - 더 높은 대역폭, 더 높은 PPS(Packet per second), 더 낮은 지연 시간 제공.
    - **EC2 Enhanced Networking이 가능한 이유**
	    1. **ENA(Elastic Network Adapter)**: 최대 100Gbps. EC2 개선을 위한 네트워킹으로 높은 대역폭을 제공하며, 초당 패킷이 높고 지연 시간이 낮다.
	    2. **Intel 82599 VF**: 최대 10Gbps(레거시). 인텔사에서 제공하는 오래된 ENA
	    
3.  **Elastic Fabric Adapter(EFA):** 

	* 고성능 컴퓨팅용 HPC 워크로드를 위해 향상된 ENA, Linux에서만 작동.
	* 노드 간 통신이나 밀접하게 결합된 작업이 유용. ex) 분산 연산
		* 이유 : MPI(Message Passing Interface) 표준 활용. 이 표준은 기본 Linux OS를 우회하여 지연 시간이 짧고 신뢰할 수 있는 안정적인 전송 제공.

### Storage (스토리지)

1. **Instance-attached storage (인스턴스 연결 스토리지)**:
    
    - **EBS**: io2 Block Express로 최대 256,000 IOPS 확장.
    - **Instance Store**: EC2 인스턴스와 연결되어 수백만 IOPS로 확장, 짧은 지연 시간.
    
2. **Network storage (네트워크 스토리지)**:
    
    - **Amazon S3**: 파일 시스템이 아닌 큰 블랍.
    - **Amazon EFS**: 전체 크기를 기준으로 IOPS 확장 또는 프로비저닝된 IOPS 사용.
    - **Lustre용 Amazon FSx**: HPC 최적화된 분산 파일 시스템, 수백만 IOPS, S3에 의해 지원됨.

### Automation and Orchestration (자동화 및 오케스트레이션)

1. **AWS Batch**:
    
    - 단일 실행이 가능한 다중 노드 병렬 작업을 지원.
    - 여러 EC2 인스턴스에 걸쳐 있는 작업을 쉽게 예약하고 실행 가능.
    
2. **AWS ParallelCluster (병렬 클러스터)**:
    
    - AWS에 HPC를 구축하기 위한 오픈 소스 클러스터 관리 툴.
    - 텍스트 파일로 구성할 수 있음.
    - VPC, 서브넷, 클러스터 유형 및 인스턴스 유형 생성 자동화.

이들 서비스를 활용하면 AWS에서 고성능 컴퓨팅 환경을 효율적으로 구축하고 관리할 수 있다.

# VI. Auto Scaling Groups

## Dynamic Scaling Policies
자동 스케일링 그룹(ASG)에서 동적 스케일링 정책은 다음과 같이 구성할 수 있다.

### Target Tracking Scaling (대상 추적 스케일링)

- **가장 간단하고 쉽게 설정 가능**:
    - 특정 지표를 목표로 설정하여 스케일링을 자동으로 관리한다.
    - 예: 평균 ASG CPU 사용률이 40%를 유지하도록 설정.

### Simple / Step Scaling (단순/단계 확장)

- **CloudWatch 경보를 기반으로 스케일링**:
    - 특정 조건이 충족되면 인스턴스를 추가하거나 제거한다.
    - 예: CPU 사용률이 70%를 초과하면 인스턴스 2개 추가.
    - 예: CPU 사용률이 30% 미만이면 인스턴스 1개 제거.

### Scheduled Actions (예약된 작업)

- **알려진 사용 패턴을 기반으로 스케일링**:
    - 특정 시간에 맞춰 자동으로 용량을 조절한다.
    - 예: 금요일 오후 5시에 최소 용량을 10으로 증가.

##  Predictive Policies
자동 스케일링 그룹(ASG)에서 예측 정책은 다음과 같이 구성할 수 있다.
### Predictive scaling (예측 스케일링)

- **지속적인 부하 예측 및 스케줄 스케일링 시간**:
    - 과거 데이터를 기반으로 향후 부하를 예측하여 스케일링 계획을 세운다.
    - 예: 특정 시간대에 예상되는 트래픽 증가에 대비해 미리 확장.

이러한 정책을 통해 AWS 환경에서 애플리케이션의 성능과 비용을 최적화할 수 있다. 필요에 따라 다양한 스케일링 정책을 조합하여 사용하면, 트래픽 변화에 유연하게 대응할 수 있다.


## Auto Scaling Groups(ASG)에서 확장하기에 적합한 주요 메트릭
자동 스케일링 그룹(ASG)에서 확장하기에 적합한 메트릭은 애플리케이션의 성능과 안정성을 보장하기 위해 중요하다. 

### CPU 사용률

- **CPUUtilization (평균 CPU 사용률)**:
    - 인스턴스 전체의 CPU 활용도를 모니터링한다.
    - 예: 평균 CPU 사용률이 70%를 초과하면 인스턴스를 추가하여 부하를 분산시킨다.

### RequestCountPerTarget

- **대상당 RequestCountPerTarget**:
    - 각 대상(예: 로드 밸런서 뒤의 EC2 인스턴스)당 요청 수를 확인한다.
    - 예: 특정 인스턴스당 요청 수가 일정 임계값을 초과하면 인스턴스를 추가하여 요청을 처리한다.
    - 인스턴스가 안정적으로 작동하는 경우 유용하다.

### Average Network In / Out (평균 네트워크 입력/출력)

- **네트워크 입력/출력**:
    - 네트워크 바인딩된 응용 프로그램의 경우 네트워크 트래픽을 모니터링한다.
    - 예: 평균 네트워크 입력/출력 값이 특정 임계값을 초과하면 인스턴스를 추가한다.

### Any custom metric (사용자 지정 메트릭)

- **사용자 정의 메트릭**:
    - CloudWatch를 사용해 애플리케이션에 특화된 메트릭을 모니터링한다.
    - 예: 특정 애플리케이션 로그의 에러 발생 횟수, 메모리 사용량, 디스크 I/O 등.
    - 이러한 사용자 정의 메트릭을 기반으로 스케일링 정책을 설정할 수 있다.

이 메트릭들을 사용하여 자동 스케일링 정책을 설정하면, 애플리케이션의 성능과 안정성을 유지하면서 효율적으로 리소스를 관리할 수 있다. 다양한 메트릭을 조합하여 사용하면 보다 정교한 스케일링 정책을 구현할 수 있다.

## Auto Scaling Groups(ASG)의 중요한 사항
자동 스케일링(Auto Scaling) 그룹을 설정하거나 관리할 때 유용한 몇 가지 중요한 사항들이다.

### Spot Fleet support

- **Spot 및 On-Demand 인스턴스 혼합 사용**:
    - 비용 절감을 위해 Spot 인스턴스를 사용하면서도 안정성을 위해 On-Demand 인스턴스를 함께 사용할 수 있다.

### Lifecycle Hooks

- **인스턴스 라이프사이클 중 특정 작업 수행**:
    - 인스턴스가 서비스에 들어가기 전 또는 종료되기 전에 특정 작업을 수행할 수 있다.
    - 예: 클린업 작업, 로그 추출, 특별한 헬스 체크 등.

### AMI 업그레이드

- **런치 구성/템플릿 업데이트**:
    - AMI를 업그레이드하려면 런치 구성 또는 템플릿을 업데이트해야 한다.
    - 이후 기존 인스턴스를 수동으로 종료해야 하며, CloudFormation을 사용하여 이를 자동화할 수 있다.
    - 또는 EC2 Instance Refresh 기능을 사용하여 자동으로 인스턴스를 새로 고칠 수 있다.

이러한 기능들은 자동 스케일링 그룹의 유연성을 높이고 관리 작업을 간소화하는 데 매우 유용하다. Spot 인스턴스와 On-Demand 인스턴스를 혼합하여 비용을 절감할 수 있으며, Lifecycle Hooks를 통해 인스턴스의 라이프사이클 동안 필요한 작업을 자동으로 수행할 수 있다. 또한, EC2 Instance Refresh 기능을 사용하여 AMI 업그레이드를 보다 쉽게 관리할 수 있다.

## Auto Scaling 주요 기능

### Instance Refresh
EC2 Auto Scaling의 Instance Refresh 기능을 사용하면 인스턴스를 자동 새로고침으로, 최신 런치 템플릿을 적용할 수 있다. 이를 통해 시스템의 가용성과 안정성을 유지하면서 인스턴스를 업데이트할 수 있다. 다음은 Instance Refresh 기능을 설정하고 사용하는 방법에 대해 설명이다.

#### 목표
- 런치 템플릿을 업데이트한 후 모든 EC2 인스턴스를 재생성하는 것.

#### Instance Refresh 기능 사용
Instance Refresh 기능을 사용하면 수동으로 인스턴스를 종료하고 다시 시작할 필요 없이, 자동으로 인스턴스를 새로 고칠 수 있다.

#### 설정 방법

1. **최소 건강 비율(Minimum Healthy Percentage) 설정**:
    
    - 새로 고침 중에도 일정 비율의 인스턴스가 건강한 상태로 유지되도록 설정할 수 있다.
    - 예: 최소 건강 비율을 80%로 설정하면, 전체 인스턴스 중 80%는 항상 가용 상태로 유지된다.
2. **워밍업 시간(Warm-up Time) 지정**:
    
    - 새 인스턴스가 시작되고 실제로 사용 가능해질 때까지의 시간을 설정한다.
    - 예: 워밍업 시간을 300초(5분)로 설정하면, 새 인스턴스가 시작된 후 5분 동안은 트래픽을 받지 않고 준비 상태에 있게 된다.

#### 설정 예시

AWS Management Console 또는 AWS CLI를 통해 Instance Refresh를 설정할 수 있습니다.

##### AWS Management Console

1. Auto Scaling 그룹을 선택합니다.
2. "Instance Refresh" 탭으로 이동합니다.
3. "Start Instance Refresh" 버튼을 클릭합니다.
4. 최소 건강 비율과 워밍업 시간을 설정합니다.
5. 설정을 저장하고 새로 고침을 시작합니다.

##### AWS CLI

bash

```bash
aws autoscaling start-instance-refresh --auto-scaling-group-name <AutoScalingGroupName> --preferences '{"MinHealthyPercentage":<Percentage>,"InstanceWarmup":<TimeInSeconds>}'
```

- `<AutoScalingGroupName>`: Auto Scaling 그룹의 이름
- `<Percentage>`: 최소 건강 비율 (예: 80)
- `<TimeInSeconds>`: 워밍업 시간 (예: 300초)

##### 예시 설정

bash

```bash
aws autoscaling start-instance-refresh --auto-scaling-group-name MyAutoScalingGroup --preferences '{"MinHealthyPercentage":80,"InstanceWarmup":300}'
```

이 설정을 통해 런치 템플릿을 업데이트하고, 모든 인스턴스를 자동으로 새로 고칠 수 있다. 이를 통해 시스템의 가용성을 유지하면서, 최신 설정을 적용할 수 있다.

### Scaling Processes
Auto Scaling 그룹에서 다양한 스케일링 프로세스를 관리할 수 있다. 이 프로세스들을 이해하고 적절히 사용하면, 애플리케이션의 가용성과 안정성을 높일 수 있다. 다음은 주요 스케일링 프로세스와 그 기능에 대한 설명이다.

#### 주요 스케일링 프로세스

1. **Launch**: 새로운 EC2 인스턴스를 그룹에 추가하여 용량을 증가시킨다.
2. **Terminate**: 그룹에서 EC2 인스턴스를 제거하여 용량을 감소시킨다.
3. **HealthCheck**: 인스턴스의 상태를 점검한다. 상태가 불량한 인스턴스를 탐지한다.
4. **ReplaceUnhealthy**: 상태가 불량한 인스턴스를 종료하고, 새로 생성하여 교체한다.
5. **AZRebalance**: 가용 영역(AZ) 간에 EC2 인스턴스 수를 균형 있게 조정한다.
6. **AlarmNotification**: CloudWatch 경보를 수신하여 스케일링 작업을 트리거한다.
7. **ScheduledActions**: 사용자가 생성한 예약된 작업을 수행한다. 예를 들어, 특정 시간에 스케일링 작업을 실행할 수 있다.
8. **AddToLoadBalancer**: 인스턴스를 로드 밸런서 또는 타겟 그룹에 추가한다.
9. **InstanceRefresh**: 인스턴스를 새로 고친다. 새로운 런치 템플릿을 적용하여 인스턴스를 업데이트한다.

#### 프로세스 일시 중지

- 필요에 따라 특정 스케일링 프로세스를 일시 중지할 수 있습니다. 예를 들어, 특정 작업을 수행하는 동안 스케일링을 일시 중지하여 예기치 않은 인스턴스 추가/제거를 방지할 수 있습니다.

#### 일시 중지 방법

##### AWS Management Console

1. Auto Scaling 그룹을 선택합니다.
2. "Activity" 탭으로 이동합니다.
3. "Suspend" 또는 "Resume" 버튼을 클릭하여 특정 프로세스를 일시 중지 또는 재개한다.

##### AWS CLI

bash

```bash
aws autoscaling suspend-processes --auto-scaling-group-name <AutoScalingGroupName> --scaling-processes <ProcessName>
```

- `<AutoScalingGroupName>`: Auto Scaling 그룹의 이름
- `<ProcessName>`: 일시 중지할 프로세스 이름 (예: Launch, Terminate 등)

bash

```bash
aws autoscaling resume-processes --auto-scaling-group-name <AutoScalingGroupName> --scaling-processes <ProcessName>
```

- `<ProcessName>`: 재개할 프로세스 이름

##### 예시 설정

bash

```bash
aws autoscaling suspend-processes --auto-scaling-group-name MyAutoScalingGroup --scaling-processes Terminate
```

- 이 명령어는 `Terminate` 프로세스를 일시 중지하여 인스턴스가 그룹에서 제거되지 않도록 한다.

bash

```bash
aws autoscaling resume-processes --auto-scaling-group-name MyAutoScalingGroup --scaling-processes Terminate
```

- 이 명령어는 `Terminate` 프로세스를 다시 활성화하여 정상 작동하도록 한다.

이와 같은 스케일링 프로세스를 적절히 관리하여, Auto Scaling 그룹의 동작을 세밀하게 제어할 수 있다.

### Health Checks
Auto Scaling 그룹에서 인스턴스의 건강 상태를 확인하는 것은 매우 중요하다. 이를 위해 다양한 헬스 체크 옵션을 제공하며, 이를 통해 시스템의 안정성을 유지할 수 있다. 다음은 Auto Scaling 그룹에서 사용 가능한 헬스 체크 옵션과 그 기능에 대한 설명이다.

#### 헬스 체크 옵션

1. **EC2 Status Checks**:
    
    - EC2 인스턴스의 하드웨어 및 소프트웨어 상태를 점검한다.
    - EC2 인스턴스 자체에서 수행되는 기본적인 상태 점검이다.
2. **ELB Health Checks (HTTP)**:
    
    - ELB(Elastic Load Balancer)가 인스턴스의 상태를 점검한다.
    - HTTP 요청을 통해 인스턴스의 응답 상태를 확인한다.
    - 로드 밸런서를 사용하는 경우, ELB 헬스 체크를 통해 인스턴스의 가용성을 보장할 수 있다.
3. **Custom Health Checks**:
    
    - 사용자 정의 헬스 체크를 통해 인스턴스의 상태를 Auto Scaling 그룹에 전달할 수 있다.
    - AWS CLI 또는 AWS SDK를 사용하여 `set-instance-health` 명령을 통해 인스턴스의 상태를 설정한다.
    - 예를 들어, 특정 애플리케이션의 상태를 점검하여 헬스 체크 결과를 Auto Scaling 그룹에 반영할 수 있다.

#### 헬스 체크 동작 방식

- Auto Scaling 그룹은 불량한 상태로 판정된 인스턴스를 종료하고, 새로운 인스턴스를 시작하여 교체한다.
- 이를 통해 건강하지 않은 인스턴스가 지속적으로 운영되는 것을 방지하고, 시스템의 가용성을 유지한다.

#### 헬스 체크 설정 시 주의사항

- 단순하고 정확한 헬스 체크를 구성하는 것이 중요하다.
- 헬스 체크가 너무 복잡하거나 지나치게 엄격하면, 정상적인 인스턴스가 불량으로 판정될 수 있다.
- 반대로 헬스 체크가 너무 느슨하면, 실제로 불량한 인스턴스가 탐지되지 않을 수 있다.

#### 헬스 체크 설정 예시

###### EC2 Status Checks 및 ELB Health Checks 설정 (AWS Management Console)

1. Auto Scaling 그룹을 선택합니다.
2. "Details" 탭에서 "Health Check Type"을 선택한다.
3. EC2, ELB, 또는 둘 다 선택할 수 있다.
4. "Health Check Grace Period"를 설정하여 헬스 체크가 시작되기 전에 대기할 시간을 지정한다.

##### Custom Health Checks 설정 (AWS CLI)

1. 사용자 정의 스크립트를 통해 인스턴스 상태를 점검한다.
2. 인스턴스 상태를 설정합니다.

bash

```bash
aws autoscaling set-instance-health --instance-id <InstanceId> --health-status <HealthStatus>
```

- `<InstanceId>`: 인스턴스 ID
- `<HealthStatus>`: `Healthy` 또는 `Unhealthy`

##### 예시 설정

bash

```bash
aws autoscaling set-instance-health --instance-id i-0123456789abcdef0 --health-status Unhealthy
```

- 이 명령어는 지정된 인스턴스를 불량 상태로 설정한다. Auto Scaling 그룹은 이 인스턴스를 종료하고 새 인스턴스를 시작한다.

적절한 헬스 체크 설정을 통해 Auto Scaling 그룹에서 인스턴스의 상태를 지속적으로 모니터링하고, 불량한 인스턴스를 자동으로 교체하여 시스템의 안정성을 유지할 수 있다.

### Auto Scaling Update Strategies
Auto Scaling 그룹에서 응용 프로그램을 업데이트하는 방법의 예시는 다음과 같다.

1. **자동 배율 그룹 유지 및 업데이트**
    
    - <u>기존 자동 배율 그룹을 유지</u>하면서 <u>같은 타겟 그룹</u>에 새 런치 템플릿을 만든다.
    - 새 템플릿으로 EC2 인스턴스를 생성하고, 이를 위해 자동 스케일링 그룹 용량을 일시적으로 늘린니다.
    - 애플리케이션 부하 분산기를 통해 두 가지 버전의 애플리케이션에 트래픽을 분산한다.
    - 새 버전이 안정적이라면 기존 인스턴스를 종료한다.

2. **새 자동 배율 그룹 생성**
    
    - <u>새로운 자동 배율 그룹을 생성</u>하고, <u>새 타깃 그룹</u>도 만든다.
    - 두 번째 타깃 그룹에 소량의 트래픽을 보내 새 애플리케이션을 테스트한다.
    - 테스트가 성공적이라면 트래픽을 점진적으로 새 그룹으로 전환하고, 기존 그룹을 제거한다.
    
3. **이중 ALB 설정**
    
    - <u>기존 ALB와 새로운 ALB를 각각 다른 자동 배율 그룹과 연결</u>한다.
    - Route 53을 사용해 클라이언트 트래픽을 두 ALB로 분산한다.
    - 새로운 ALB를 독립적으로 테스트하고 점진적으로 트래픽을 전환한다.



# V. Spot Instances & Spot Fleet
## EC2 Spot Instances

* 온디맨드 인스턴스에 비해 최대 90% 할인 가능
* 최대 스팟 가격을 정의하고 현재 스팟 가격이 최대 가격보다 낮을 때 인스턴스 획득
* 시간당 스팟 가격은 수요와 용량에 따라 변동
* 현재 스팟 가격이 최대 가격을 초과할 경우, 인스턴스를 중지하거나 종료할 수 있으며 2분의 유예 기간 제공
* 배치 작업, 데이터 분석 또는 실패에 견딜 수 있는 작업에 사용
* 중요한 작업이나 데이터베이스에는 적합하지 않음

## Spot Fleets(스팟 플릿)
* 스팟 플릿 = 스팟 인스턴스 세트 + (선택 사항) 온디맨드 인스턴스
* 스팟 플릿은 가격 제약 조건 내에서 목표 용량을 충족하려고 시도
* 가능한 런치 풀 정의: 인스턴스 유형(m5.large), 운영체제(OS), 가용 영역(Availability Zone)
* 여러 런치 풀을 가질 수 있어 플릿이 선택 가능
* 용량 또는 최대 비용에 도달하면 스팟 플릿은 인스턴스 실행을 중지
* **스팟 인스턴스 할당 전략**:
	- lowestPrice: 가장 낮은 가격의 풀에서 (비용 최적화, 짧은 작업)
	- diversified: 모든 풀에 분산 (가용성에 좋음, 긴 작업)
	- capacityOptimized: 인스턴스 수에 대해 최적 용량을 가진 풀
	- priceCapacityOptimized (권장): 가장 높은 용량을 가진 풀에서, 그 후 가장 낮은 가격의 풀 선택 (대부분의 작업에 최적), 스팟 플릿을 통해 가장 낮은 가격의 스팟 인스턴스를 자동으로 요청 가능

## EC2 Spot Instances와 Spot Fleets의 차이점
### EC2 Spot Instances

- **단일 인스턴스**: 스팟 인스턴스는 단일 EC2 인스턴스를 요청하는 방식이다.
- **가격 최적화**: 사용자는 스팟 인스턴스에 대해 지불할 최대 가격을 설정하고, 현재 스팟 가격이 이에 미치지 못하면 인스턴스를 획득할 수 있다.
- **유연성**: 스팟 인스턴스는 주로 비용 절감과 일시적인 작업에 사용된다. 예를 들어, 배치 작업, 데이터 분석, 테스트 환경 등 실패에 견딜 수 있는 작업에 적합하다.
- **관리**: 사용자는 각 인스턴스를 개별적으로 관리해야 한다.

### Spot Fleets)

- **다중 인스턴스 관리**: 스팟 플릿은 여러 스팟 인스턴스와 선택적으로 온디맨드 인스턴스를 포함하는 인스턴스 집합을 관리하는 방식이다.
- **자동화 및 최적화**: 스팟 플릿은 목표 용량을 설정하고, 가격 제약 조건 내에서 이를 충족하려고 시도한다. 다양한 인스턴스 유형, 운영 체제, 가용 영역을 포함한 다양한 런치 풀을 정의할 수 있어 더 높은 유연성과 가용성을 제공한다.
- **할당 전략**: 스팟 플릿은 여러 할당 전략을 제공한다. 예를 들어, lowestPrice, diversified, capacityOptimized, priceCapacityOptimized 등 다양한 전략을 통해 비용 최적화, 가용성, 용량 최적화를 달성할 수 있다.
- **자동 확장**: 스팟 플릿은 자동 확장 기능을 지원하여, 특정 조건에 따라 인스턴스를 자동으로 늘리거나 줄일 수 있다.
- **단일 관리**: 스팟 플릿은 하나의 엔티티로 취급되어, 복수의 인스턴스를 중앙에서 관리할 수 있다.

### 요약

- **EC2 스팟 인스턴스**: 단일 인스턴스를 저렴한 가격에 사용하고자 할 때 적합.
- **스팟 플릿**: 다중 인스턴스를 자동으로 관리하고, 다양한 인스턴스 유형과 전략을 통해 비용 절감과 가용성을 극대화하고자 할 때 적합.

# VI. Amazon ECS - Elastic Container Service
Docker는 컨테이너 기술의 핵심을 제공하고, ECS는 이러한 Docker 컨테이너를 대규모로 관리하고 오케스트레이션하는 데 사용되는 서비스이다.

## Docker
- **소프트웨어 개발 플랫폼**: Docker는 앱을 배포하고 관리하는 소프트웨어 개발 플랫폼이다.
- **컨테이너 기반**: Docker는 애플리케이션을 모든 OS에서 실행할 수 있는 컨테이너에 포장하여 배포한다.
- **일관된 실행 환경**: 애플리케이션은 실행 위치에 관계없이 동일한 환경에서 실행된다.
- **시스템 호환성 문제 해결**: 모든 시스템에서 호환성 문제 없이 예측 가능한 동작을 보인다.
- **작업량 감소**: 개발, 테스트, 배포 과정에서의 작업량을 줄여준다.
- **유지보수 및 구축 용이**: 애플리케이션의 유지보수 및 구축이 용이하다.
- **언어/OS/기술 무관**: 모든 프로그래밍 언어, 운영 체제, 기술과 함께 작동한다.
- **자원 제어**: 컨테이너에 할당되는 메모리와 CPU 양을 제어할 수 있다.
- **빠른 확장성**: 컨테이너를 매우 빠르게 위아래로 확장할 수 있다(초 단위).
- **효율성**: 가상 머신보다 더 효율적으로 자원을 사용한다.

### Docker의 주요 특징

1. **컨테이너(Container)**:
    
    - 컨테이너는 애플리케이션과 그 실행 환경을 함께 캡슐화하여, 어디서나 일관되게 실행될 수 있도록 한다.
    - 가볍고, 빠르게 시작할 수 있으며, 시스템 자원을 효율적으로 사용한다.
2. **이미지(Image)**:
    
    - Docker 이미지는 컨테이너의 실행 환경을 정의하는 템플릿이다.
    - 이미지는 불변이며, 동일한 이미지를 사용하면 항상 동일한 실행 환경을 보장한다.
3. **도커 허브(Docker Hub)**:
    
    - Docker Hub는 Docker 이미지를 저장하고 공유할 수 있는 클라우드 기반 레지스트리이다.
    - 다양한 공식 이미지와 커뮤니티 이미지를 제공하여, 쉽게 애플리케이션을 시작할 수 있다.
4. **도커 파일(Dockerfile)**:
    
    - Dockerfile은 이미지를 빌드하기 위한 명령어 모음이다.
    - 코드와 의존성을 정의하고, 이미지를 자동으로 생성할 수 있다.

### Docker의 장점

- **이식성**: 컨테이너를 사용하면 애플리케이션을 개발 환경에서 프로덕션 환경으로 쉽게 이동할 수 있다.
- **효율성**: 가상 머신보다 더 적은 자원을 사용하며, 빠르게 시작할 수 있다.
- **유연성**: 다양한 언어와 프레임워크 지원, 여러 클라우드 플랫폼에서 사용 가능하다.
- **자동화**: CI/CD 파이프라인에 쉽게 통합하여 자동화된 배포와 테스트가 가능다.

## AWS의 Docker Containers 관리
AWS는 다양한 요구에 맞춰 여러 컨테이너 관리 옵션을 제공하여, 사용자가 필요에 따라 적합한 서비스를 선택할 수 있게 한다.
### Amazon Elastic Container Service (Amazon ECS)

- Amazon ECS는 완전 관리형 컨테이너 오케스트레이션 서비스로, AWS 환경에서 Docker 컨테이너를 쉽게 실행하고 확장할 수 있다.
- **특징**:
    - AWS와 긴밀하게 통합되어 있어 높은 가용성과 보안성을 제공한다.
    - EC2 인스턴스 또는 AWS Fargate를 사용하여 컨테이너를 실행할 수 있다.
    - 사용이 간편하고, AWS의 다른 서비스와 원활하게 연동된다.

### Amazon Elastic Kubernetes Service (Amazon EKS)

- Amazon EKS는 Kubernetes를 관리하고 오케스트레이션하는 서비스로, AWS에서 Kubernetes 클러스터를 손쉽게 운영할 수 있다.
- **특징**:
    - 오픈 소스 Kubernetes와 완벽하게 호환된다.
    - 자동화된 업그레이드, 패치 관리, 고가용성을 제공한다.
    - EC2 인스턴스 또는 AWS Fargate를 사용하여 컨테이너를 실행할 수 있다.

### AWS Fargate

- AWS Fargate는 서버리스 컨테이너 실행 환경으로, 인프라를 관리할 필요 없이 컨테이너를 실행할 수 있다.
- **특징**:
    - 서버리스로 인프라 관리 부담이 없다.
    - ECS 및 EKS와 통합되어 사용 가능하다.
    - 자동으로 스케일링되며, 사용한 만큼만 비용을 지불한다.

### ECS 및 EKS 작업

- ECS와 EKS를 통해 각각의 작업(Task)을 정의하고 실행할 수 있다.
- **특징**:
    - ECS 작업: 특정 컨테이너 이미지를 기반으로 작업을 정의하고, 이를 클러스터 내에서 실행한다.
    - EKS 작업: Kubernetes의 Pod를 기반으로 작업을 정의하고, 이를 클러스터 내에서 실행한다.

### 요약

- **Amazon ECS**: AWS에서 Docker 컨테이너를 관리하고 오케스트레이션하는 완전 관리형 서비스.
- **Amazon EKS**: Kubernetes 기반의 컨테이너 오케스트레이션 서비스로, AWS 환경에서 Kubernetes 클러스터를 운영.
- **AWS Fargate**: 서버리스 컨테이너 실행 환경으로, 인프라 관리 없이 컨테이너 실행.
- **ECS 및 EKS 작업**: 각각의 환경에서 작업을 정의하고 실행하는 방식.



# VII. Amazon ECR - Elastic Container Registry

# VIII. Amazon EKS - Elastic Kubernetes Service

