*  대규모 데이터를 저장하고 처리하기 위한 오픈소스 프레임워크 
*  분산 저장 및 분산 처리를 통해 대용량 데이터 세트를 효율적으로 관리 할 수 있다.

# Hadoop의 구성요소 #Hadoop

1. HDFS(Hadoop Distributed File System) : 대규모 데이터를 분산 저장하기 위한 파일 시스템이다.
데이터를 작은 블록으로 나누어 여러 노드에 분산 저장 하므로, 대용량 데이터를 효율적으로 처리 할 수 있다. 주로 클러스터 내에서 데이터 처리 중간 결과를 저장하는데 사용하는 임시저장소(Temporary Storage) 역할을 수행한다. 


### Apach Hive
대규모 데이터 처리를 위해 설계된 데이터 웨어하우스 시스템으로,
Hadoop 분산 파일시스템(HDFS) 위에서 동작한다. Hive는 SQL과 유사한 언어인
HiveQL을 사용하여 데이터를 쿼리하고 관리할 수 있게 해주며, 대용량 데이터 세트를
쉽게 분석할 수 있는 편리한 방법을 제공한다. 

