*  대규모 데이터를 저장하고 처리하기 위한 오픈소스 프레임워크 
*  분산 저장 및 분산 처리를 통해 대용량 데이터 세트를 효율적으로 관리 할 수 있다.

# Hadoop의 구성요소 #Hadoop

1. HDFS(Hadoop Distributed File System) : 대규모 데이터를 분산 저장하기 위한 파일 시스템이다.
데이터를 작은 블록으로 나누어 여러 노드에 분산 저장 하므로, 대용량 데이터를 효율적으로 처리 할 수 있다. 주로 클러스터 내에서 데이터 처리 중간 결과를 저장하는데 사용하는 임시저장소(Temporary Storage) 역할을 수행한다. 

### Apach Hive
대규모 데이터 처리를 위해 설계된 데이터 웨어하우스 시스템으로,
Hadoop 분산 파일시스템(HDFS) 위에서 동작한다. Hive는 SQL과 유사한 언어인
HiveQL을 사용하여 데이터를 쿼리하고 관리할 수 있게 해주며, 대용량 데이터 세트를
쉽게 분석할 수 있는 편리한 방법을 제공한다. 

# Hadoop의 노드 타입
1. **NameNode**
    - **역할**: HDFS의 메타데이터를 관리한다. 파일 시스템의 네임스페이스를 유지하고 데이터 블록의 위치를 추적한다.
    - **기능**: 파일 접근 요청을 처리하고, 파일 시스템 트리와 각 파일의 블록 정보를 관리한다.
2. **ResourceManager**
    - **역할**: YARN의 핵심 구성 요소로, 클러스터 자원을 관리한다.
    - **기능**: 애플리케이션의 자원 요구를 스케줄링하고 할당한다.
3. **DataNode**
    - **역할**: 실제 데이터 블록을 저장한다.
    - **기능**: NameNode의 지시에 따라 데이터 블록을 읽고 쓴다
4. **NodeManager**
    - **역할**: 각 노드에서 컨테이너의 실행을 관리한다.
    - **기능**: ResourceManager와 통신하여 자원 사용을 보고하고, 컨테이너를 시작 및 중지한다. 
5. **Secondary NameNode**
    - **역할**: NameNode의 체크포인트를 생성하여 메타데이터의 스냅샷을 보관한다.
    - **기능**: NameNode의 장애에 대비한 보조적인 역할을 수행한다.









