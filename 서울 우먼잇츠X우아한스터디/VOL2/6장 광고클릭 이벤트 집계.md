#### RTB(Real-Time Bidding) 실시간 경매
경매절차를 통해 광고를 올릴 공간 지면(inventory)를 거래한다. 
지면수요자 측(광고주)이 DSP(Demand-Side Platform, 수요자 플랫폼)을 통해 광고 거래소에
접속한다.
지면공급자 측(광고할 위치를 가진 공급자)이 SSP(Supply-Side Plaform, 공급자 플랫폼)을 통해 광고거래소에 지면을 등록한다. 

#### RTB에선 뭐가 중요한가?
1. 속도 : 보통 1초내에 모든 프로세스가 마무리 되어야한다.
2. 데이터의 정확성 : 광고 클릭 이벤트 집계는 온라인 광고가 얼마나 효율적이었는지 측정하는 결정적인 역할을 하며, 결과적으로 광고주가 얼마나 돈을 지불해야하는지 영향을 준다. 클릭집계 결과에 따라 광고 예산 조정, 타깃 그룹이나 키워드 변경 등 광고전략을 수정하기도 한다. 
3. CTR(Click-Through Rate , 클릭률) 
	 광고 노출 수 대비 클릭 수의 비율을 나타낸다. 
	 광고의 관심도와 효과성을 측정할 수 있다.
	 일반적으로 CTR이 높을수록 광고 성과가 좋다고 볼 수 있다. 

4. CVR(Conversion Rate 전환률)
	 광고 노출 또는 클릭 수 대비 실제 전환 수의 비율을 나타낸다.
	 **전환**은 **구매, 회원가입, 문의** 등 광고주가 원하는 특정행동을 의미한다. 
	 광고 캠패인의 최종목표 달성여부를 보여주는 지표이다. 
	 일반적으로 CTR이 높을수록 광고 효과가 좋다고 볼 수 있다.

#### 기능 요구사항
* 지난 M 분동안의 ad_id 클릭 수 집계
* 매분 가장 많이 클릭된 상위 100개 광고 아이디를 반환
* 다양한 속성에 따른 집계 필터링 지원
* 데이터의 양은 페이스북이나 구글규모
#### 비기능 요구사항
* 집계결과 정확성은 데이터가 RTB(Real-Time Bidding) 및 광고 과금에 사용되니 중요
* 지연되거나 중복된 이벤트를 적절히 처리해야함
* 견고성(reliablity) : 부분적인 장애는 감내할 수 있어야함. 
* 지연시간 요구사항 : 전체처리 시간은 최대 수 분을 넘지 않아야함. 

#### 질의 API 설계 
API 1: 지난 M분간 각 ad_id에 발생한 클릭 수 

API 2 : 지난 M분간 가장 많은 클릭이 발생한 상위N개 ad_id 목록


#### 맵리듀스
대규모 데이터 처리와 분석을 위한 프로그래밍 모델이자 프레임워크입니다. 주로 빅데이터 환경에서 사용되며, 다음과 같은 두 단계로 구성됩니다:

1. **맵(Map) 단계**:
    - 입력 데이터를 여러 조각으로 나누어 각 조각을 처리한다.
    - 이 단계에서 데이터는 키-값 쌍으로 변환되며, 필요한 정보만 추출된다.
2. **리듀스(Reduce) 단계**:
    - 맵 단계에서 생성된 키-값 쌍을 집계한다.
    - 같은 키를 가진 값들을 모아서 최종 결과를 생성한다. 

맵리듀스에서 맵 노드(Map Node)는 입력 데이터를 처리하고 변환하여 집계 노드(Reduce Node)로 분배하는 중요한 역할을 합니다. 이 과정은 다음과 같은 단계로 이루어집니다:

1. **입력 데이터 수집**:
    - 맵 노드는 대량의 입력 데이터를 받아온다. 이 데이터는 로그 파일, 데이터베이스 등 다양한 소스에서 올 수 있다.
2. **필터링**:
    - 맵 노드는 입력 데이터에서 필요한 정보만 추출한다. 예를 들어, 광고 클릭 이벤트의 경우, 클릭 시간, 사용자 ID, 광고 ID 등 필요한 필드를 선택하여 필터링한다.
3. **변환**:
    - 필터링된 데이터를 키-값 쌍으로 변환한다. 이 과정에서 각 데이터 항목에 대해 특정 키를 할당하고, 그에 관련된 값을 정의한다. 예를 들어, 광고 ID를 키로 하고 클릭 수를 값으로 설정할 수 있다.
4. **중간 결과 생성**:
    - 변환된 데이터는 중간 결과로 생성된다. 이 중간 결과는 맵 단계에서 처리된 모든 데이터의 집합이다.
5. **분배**:
    - 맵 노드는 중간 결과를 집계 노드로 분배한다. 이때, 키를 기준으로 데이터를 그룹화하여 같은 키를 가진 값들이 동일한 집계 노드로 전달되도록 한다. 이를 통해 **리듀스 단계에서 같은 키에 대한 데이터가 모여 효율적으로 집계될 수 있다.**

이 과정을 통해 맵 노드는 대량의 데이터를 효과적으로 처리하고, 리듀스 단계에서 필요한 데이터 형식을 갖춘 결과를 생성하여 분배하게 된다. 이러한 방식은 대규모 데이터의 병렬 처리와 효율적인 분석을 가능하게 한다.

**집계노드들이 카프카의 파티션을 직접 구독하지않고 사이에 맵노드를 두는 이유**
카프카는 데이터의 생성방식에 대한 제어권을 따로 구성하지 않을 가능성이 높기 때문이다. 
= 카프카는 여러 producer에게 동일한 ad_id를 가진 이벤트가 서로 다른 파티션에 저장될 가능성이 있다. 이 상황에서 집계노드가 카프카를 직접 구독하게 되면 집계과정에서 중복된 데이터가 포함될 가능성이 있다. = 맵노드는 이벤트 데이터를 필터링하고 변환하여 동일한 `ad_id`를 가진 데이터들이 하나의 집계 노드로 전달되도록 합니다. 이를 통해 중복된 이벤트가 집계 결과에 포함되지 않도록 할 수 있다. 

**맵노드** : 카프카에서 전달된 데이터를 ad_id % 3 를 기준으로 분배해서 집계노드들에게 전달한다.
**집계노드** : 집계해서 리듀스노드에 전달
**리듀스노드** : 집계노드들에게 전달받은 데이터를 기준으로 최종결과를 축약한다. 


#### 주요사용사례







